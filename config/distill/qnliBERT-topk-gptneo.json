{   
    "experiment_name":"qnli-topk-gptneo",

    "batch_size": 8,
    "retriever": "topk",
    "retriever_base": "bert-base-uncased",
    "student": "EleutherAI/gpt-neo-2.7B",
    "shots": [32, 16, 8, 4, 1],

    "train_path":"data/qnli/qnli-train.jsonl",
    "val_path": null,
    "test_path": "data/qnli/qnli-test.jsonl",
    "task_description": "Task Instruction: Recognizing textual entailment between these 2 texts.\nLabel Space: {entailment, not_entailment}",

    "data_columns": {
        "input_columns": ["text"],
        "output_columns": ["label"]
    },

    "ice_dict":{
        "sequence": "</E>Texts: </text>\nAnswer: </Label1> is </1>%, </Label2> is </2>%.",
        "binning": "</E>Texts: </text>\nAnswer: </Label1> is likely, </Label2> is not likely"
    },

    "template_dict": {
        "0" : "</E>Texts: </text>\nAnswer: entailment",
        "1" : "</E>Texts: </text>\nAnswer: not_entailment"
    },

    "label_dict": {
        "0": "entailment",
        "1": "not_entailment"
    },

    "column_token_map": {
        "sequence":{"text": "</text>", "0": "</1>", "Label1": "</Label1>", "1": "</2>", "Label2" : "</Label2>"},
        "binning":{"text": "</text>", "Label1": "</Label1>", "Label2": "</Label2>"},
        "GT": {"text": "</text>"}
    }
}