{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23a8c668",
   "metadata": {},
   "source": [
    "## Generate raw dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ed0c91-47b7-4c99-b61e-92fd57933be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas pyarrow scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4be109bf-f9cd-4d23-b5b2-c3018c241c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "def parquet_to_jsonl(jsonpath_or_parquet_pattern, jsonl_file_path, is_parquet=True, split=False, splitted_output_path=None):\n",
    "    if is_parquet:\n",
    "        # Use glob to find all files matching the pattern\n",
    "        parquet_files = glob.glob(jsonpath_or_parquet_pattern)\n",
    "\n",
    "        # Initialize an empty DataFrame\n",
    "        combined_df = pd.DataFrame()\n",
    "\n",
    "        # Iterate through each file and append to the DataFrame\n",
    "        for file in parquet_files:\n",
    "            df = pd.read_parquet(file)\n",
    "            combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "    \n",
    "    else:\n",
    "        with open(jsonpath_or_parquet_pattern) as f:\n",
    "            combined_df = pd.read_json(f, lines=True)\n",
    "\n",
    "    # Convert the combined DataFrame to JSON Lines and write to a file\n",
    "    if split:\n",
    "        df, splitted_df = train_test_split(combined_df, test_size=0.1, random_state=42)\n",
    "        df.to_json(jsonl_file_path, orient='records', lines=True)\n",
    "        splitted_df.to_json(splitted_output_path, orient='records', lines=True)\n",
    "    else:\n",
    "        combined_df.to_json(jsonl_file_path, orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847e54d4",
   "metadata": {},
   "source": [
    "`jsonpath_or_parquet_pattern`: Provide pattern of a path to the `parquet` file or a path to the `jsonl` file\n",
    "- set `is_parquet=False` if providing `jsonl` file path\n",
    "\n",
    "`jsonl_file_path`: path to the output `jsonl` file\n",
    "\n",
    "`split`: set to `True` if it needs a split (validation set doesn't exist)\n",
    "\n",
    "`splitted_output_path`: path to the splitted output `jsonl` file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc94bce",
   "metadata": {},
   "source": [
    "### If using parquet file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb091340-5089-4686-a32d-e1414494ad8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "jsonpath_or_parquet_pattern = '../data/agnews/train-*.parquet'  # parquet file pattern\n",
    "jsonl_file_path = 'train.jsonl'\n",
    "splitted_output_path = 'valid.jsonl'\n",
    "parquet_to_jsonl(jsonpath_or_parquet_pattern, jsonl_file_path, is_parquet=True, split=True, splitted_output_path=splitted_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41abe07d-1114-4082-87f4-21996f1b29b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "jsonpath_or_parquet_pattern = '../data/agnews/test-*.parquet' # parquet file pattern\n",
    "jsonl_file_path = 'test.jsonl'\n",
    "parquet_to_jsonl(jsonpath_or_parquet_pattern, jsonl_file_path, is_parquet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241d5043",
   "metadata": {},
   "source": [
    "### If using jsonl file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b4feb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "jsonpath_or_parquet_pattern = '../data/trec/trec_train.jsonl'\n",
    "jsonl_file_path = 'train.jsonl'\n",
    "splitted_output_path = 'valid.jsonl'\n",
    "parquet_to_jsonl(jsonpath_or_parquet_pattern, jsonl_file_path, is_parquet=False, split=True, splitted_output_path=splitted_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a3ddf7",
   "metadata": {},
   "source": [
    "### Push to hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba9e9a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"\"\n",
    "val_path = \"\"\n",
    "test_path = \"\"\n",
    "\n",
    "dataset_name = \"ICKD/<replace-with-dataset-name>-raw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b73ca1a-b070-464e-a808-02c693dc661b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict, load_dataset\n",
    "\n",
    "dataset = load_dataset(\"json\", data_files={\"train\":train_path, \"valid\":val_path, \"test\": test_path})\n",
    "dataset.push_to_hub(dataset_name, private=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf81d4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
